<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="./files/css/jemdoc.css" type="text/css" />
<script src="jquery.min.js"></script>
<title>Kevin Riou</title>

<SCRIPT type=text/javascript>
<!--
// Toggle Display of BibTeX
function toggleBibtex(articleid) {
  var bib = document.getElementById(articleid);
  // Toggle 
    if(bib.style.display == "none") {
      bib.style.display = "";
    }
    else {
      bib.style.display = "none";
    }
}
-->
</SCRIPT>
</head>
 
 
<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable"><tr><td>
<a href="./"><img src="./files/imgs/me_1.jpg" alt="" height="215px" /></a>&nbsp;</td>
<td align="left"><p><a href="./"><font size="4">Kevin Riou</font></a><br />
<i> PhD in Computer Science | Exploring Entrepreneurship</i>
<br /><br />
<a href="https://www.univ-nantes.fr/" target="_blank">Nantes Universit√©</a><br />
<br />
Location: Nantes, France <br />
<class="staffshortcut">
 <!-- <A HREF="#News">News</A> |  -->
 <A HREF="#Education">Education</A> | 
 <A HREF="#Experience">Experience</A> |
 <A HREF="#Publications">Publications</A> | 
 <A HREF="#Services">Services</A> 
<br />
<br />
 
Email: kevin.riou97@gmail.com <br />
[<a href="https://scholar.google.com/citations?user=ylnzTogAAAAJ&hl=en" target="_blank">Google Scholar</a>]
[<a href="https://www.linkedin.com/in/kevin-riou/" target="_blank">Linkedin</a>]
[<a href="http://www.ls2n.fr/" target="_blank">Research Lab</a>]
</td></tr></table>



<A NAME="News"><h2>About Me</h2></A>
<font size="2"> 
<p style="text-align: justify;">
  My interest in embodied AI began in 2018 during my M.Sc. (engineering school), where I proposed and led a project on a fruit-harvesting robot.
  Working with Prof. <a href="https://scholar.google.com/citations?user=llgwlUgAAAAJ&hl=en&oi=ao" target="_blank">Patrick Le Callet</a>, we developed <strong>few-shot learning models</strong> to detect new fruits from minimal examples. While the computer vision worked well, manually programming a robot to crop each new fruit variety proved a major bottleneck.
  This challenge led me to focus on <strong>imitation learning</strong> for my PhD‚Äîa promising approach to bypass the need for task-specific programming in robotics.
  </p>
  <p style="text-align: justify;"></p>
  We therefore defined a PhD project with Prof. <a href="https://scholar.google.com/citations?user=llgwlUgAAAAJ&hl=en&oi=ao" target="_blank">Patrick Le Callet</a> and Dr. <a href="https://scholar.google.com/citations?hl=en&user=tyUbmQgAAAAJ" target="_blank">Kevin Subrin</a>, respectively my main and co-supervisors.
  The project focused on enabling robots to understand human video demonstrations and subsequently reproducing demonstrated tasks within their own action space, even in new environments.
  This is what we called <strong>"Embodiment and Environment Agnostic Imitation Learning for robots"</strong>.
</p>
<p style="text-align: justify;"></p>
While we were building my PhD project and searching for fundings, from 2020 to 2021, I worked at <a href="https://capacites.fr/" target="_blank">Capacit√©s</a> on <strong> tactile exploration</strong> strategies learnt by <strong>reinforcement learning</strong>.
The ultimate goal was to develop a mine sweeping robot that could explore and recognize objects burried in the ground using tactile sensors.
It was a great opportunity to apprehend the challenges associated with embodied AI and real world robotics applications.
</p>
<p style="text-align: justify;">
In october 2021, I started my PhD at <a href="https://www.univ-nantes.fr/" target="_blank">Nantes Universit√©</a> in the <a href="http://www.ls2n.fr/" target="_blank">LS2N</a> lab.
I defended this PhD in January 2025 <a href="https://youtu.be/GCxdW27dhO4" target="_blank">üé• [Recording Link] üé•</a>.
This project involved <strong>3D Human Pose Estimation, Action Recognition, 0-shot object detection/segmentation with large vision-and-language models, and diverse imitation learning strategies.</strong>

<p style="text-align: justify;">
  Below are teasers of some of the solutions we developed during my PhD:
</p>



</p>
</font>

<br />
<br />
<!-- <A HREF="#News">News</A> |  -->
  <!-- prepare 3 titles for the 3 videos:  -->
  <!-- <video width="330"  controls autoplay muted loop>
    <source src="files/imgs/video_3DHPE.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video> 
  <video width="330"  controls autoplay muted loop>
    <source src="files/imgs/video_these_mv_fine_manip.mp4" type="video/mp4">
  Your browser does not support the video tag.
  </video>
  <video width="330" controls autoplay muted loop>
    <source src="files/imgs/il.mp4" type="video/mp4">
  Your browser does not support the video tag.
  </video> 
  <br />
  <br /> -->

  <style>
    .video-container {
      display: inline-block;
      text-align: center;
      margin: 5px;
      border: 2px solid black;
      padding: 5px;
      border-radius: 5px;
    }
    .video-caption {
      font-size: 14px;
      font-weight: bold;
      margin-bottom: 5px;
    }
  </style>
  
  <div class="video-container">
    <div class="video-caption">Multi-View 3D Human Pose Estimation</div>
    <video width="310" controls autoplay muted loop>
      <source src="files/imgs/video_3DHPE.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>
  
  <div class="video-container">
    <div class="video-caption">Scene Understanding</div>
    <video width="310" controls autoplay muted loop>
      <source src="files/imgs/video_these_mv_fine_manip.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>
  
  <div class="video-container">
    <div class="video-caption">Imitation Learning</div>
    <video width="310" controls autoplay muted loop>
      <source src="files/imgs/il.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>
  
  <br /><br />
  

  <!-- <td height="100" align="right">
    <img src="files/imgs/tactile_sensor.png" width="150" align="right"/>
  </td> -->

<!-- <p style="text-align: justify;"></p>
This desire to work on learning/AI for robotics started during my M.sc. degree (engineering school) where I proposed and conducted a project on a fruit harvesting robot. 
During this project, where I already worked with Prof. <a href="https://scholar.google.com/citations?user=llgwlUgAAAAJ&hl=en&oi=ao" target="_blank">Patrick Le Callet</a>, we mostly focused on few-shot solutions trained to detect new fruits form very few examples.
While the computer vision part was successful, it was clear that programming the robot to manipulate each and every fruit was a huge bottleneck.
This is why I decided to focus on imitation learning for my PhD, as it is a promising solution to avoid the systematics of programming of robots for each new task.
</p> -->



<A NAME="Education"><h2>Education</h2></A>
<font size="2"> 
<ul>
<li> 2021 - 2025 &nbsp;&nbsp;&nbsp; Ph.D. in <a href="https://www.univ-nantes.fr/" target="_blank">Nantes Universit√©</a>, <a href="http://www.ls2n.fr/" target="_blank">LS2N</a>.</li>
<li> 2017 - 2020 &nbsp;&nbsp;&nbsp; Master of Engineering in Electronics
  and Digital Technologies in <a href="https://www.univ-nantes.fr/" target="_blank">Nantes Universit√©</a>.</li>
<li> 2015 - 2017 &nbsp;&nbsp;&nbsp; Preparatory Classes in Math-Physics in Lyc√©e Kerichen, Brest.</li>
</ul>
</font>

<A NAME="Experience"><h2>Experience</h2></A>
<!-- <font size="2"> 
<ul>
<li>Aug. 2023 - Oct. 2023 &nbsp;&nbsp;&nbsp; Ph.D. intern in <a href="https://www.nii.ac.jp/en/" target="_blank">National Institute of Informatics (Japan)</a> with Prof. <a href="https://scholar.google.com/citations?user=r7ZaWDUAAAAJ&hl=en&oi=ao" target="_blank">Akihiro Sugimoto</a></li>
<li>Oct. 2020 - Oct. 2021 &nbsp;&nbsp;&nbsp; Research Engineer in <a href="https://capacites.fr/" target="_blank">Capacit√©s (France)</a></li>
<li>Feb. 2020 - Aug. 2020 &nbsp;&nbsp;&nbsp; M.sc. internship in <a href="https://www.st.com/content/st_com/en.html" target="_blank">STMicroelectronics (France)</a></li>
<li>June 2019 - Aug. 2019 &nbsp;&nbsp;&nbsp; M.sc. internship in <a href="https://www.upes.ac.in/" target="_blank">UPES (India)</a></li>
</ul>
</font> -->
<font size="2">
  <style>
    .experience-list {
      list-style-type: disc;
    }
    .experience-item {
      display: list-item;
    }
    .date {
      display: inline-block;
      white-space: nowrap;
      min-width: 140px;
    }
    .experience-description {
      display: inline;
    }
  </style>
  
  <ul class="experience-list">
    <li class="experience-item">
      <span class="date">Aug. 2023 - Oct. 2023</span>
      <span class="experience-description">Ph.D. intern in <a href="https://www.nii.ac.jp/en/" target="_blank">National Institute of Informatics (Japan)</a> with Prof. <a href="https://scholar.google.com/citations?user=r7ZaWDUAAAAJ&hl=en&oi=ao" target="_blank">Akihiro Sugimoto</a></span>
    </li>
    <li class="experience-item">
      <span class="date">Oct. 2020 - Sept. 2021</span>
      <span class="experience-description">Research Engineer in <a href="https://capacites.fr/" target="_blank">Capacit√©s (France)</a></span>
    </li>
    <li class="experience-item">
      <span class="date">Feb. 2020 - Aug. 2020</span>
      <span class="experience-description">M.Sc. internship in <a href="https://www.st.com/content/st_com/en.html" target="_blank">STMicroelectronics (France)</a></span> with Dr. <a href="https://scholar.google.com/citations?user=kRs98R0AAAAJ&hl=fr" target="_blank">Arnaud Rosay</a></span>.
    </li>
    <li class="experience-item">
      <span class="date">June 2019 - Aug. 2019</span>
      <span class="experience-description">M.Sc. internship in <a href="https://www.upes.ac.in/" target="_blank">UPES (India)</a></span>
    </li>
  </ul>
  </font>
  
  
  
  

<A NAME="Publications"><h2>Publications</h2></A>
<p><b>3D Human Pose Estimation</b>: </p>
<font size="2"> 
    <table>
        <tbody>
          <tr>
            <td  align="left">
                <img src="files/imgs/papers/tim_unsup.jpg" width="310" />
            </td>
            <td height="92" style="text-align:left;">
                <p style="text-indent: 0rem;margin-left: 0rem;">
        <a>Geometric Consistency-Guaranteed Spatio-Temporal Transformer for Unsupervised Multi-View 3D Pose Estimation</a>
        <br/>
        Kaiwen Dong, <u>Kevin Riou</u>, Jingwen Zhu, Andreas Pastor, Kevin Subrin, Yu Zhou, Xiao Yun, Yanjing Sun, Patrick Le Callet
        <br/>
        IEEE Transactions on Instrumentation and Measurement (<b>TIM</b>), 2024.
        <br/>
        Keywords: <strong>3D human pose estimation, multi-view and temporal transformer, unsupervised learning, scene pose estimation</strong>.
        <br/>
        [<a href="https://ieeexplore.ieee.org/abstract/document/10663570" target="_blank">PDF</a>]
        [<a href="javascript:toggleBibtex('dong2024geometric')"   target=_self> Bibtex</a>]  
        <div id=dong2024geometric class=blockcontent style="DISPLAY: none">
            <pre style="white-space: pre-wrap;">
              @article{dong2024geometric,
                title={Geometric Consistency-Guaranteed Spatio-Temporal Transformer for Unsupervised Multi-View 3D Pose Estimation},
                author={Dong, Kaiwen and Riou, K{\'e}vin and Zhu, Jingwen and Pastor, Andr{\'e}as and Subrin, K{\'e}vin and Zhou, Yu and Yun, Xiao and Sun, Yanjing and Le Callet, Patrick},
                journal={IEEE Transactions on Instrumentation and Measurement},
                year={2024},
                publisher={IEEE}
              }              
              
            </pre>
        </div> 
    </span>
    </p>
            </td>
        </tr>


            <tr>
                <td  align="left">
                    <img src="files/imgs/papers/icip_hall6.png" width="310" />
                </td>
                <td height="92" style="text-align:left;">
                    <p style="text-indent: 0rem;margin-left: 0rem;">
            <a>Evaluating 3d human pose estimation in occluded multi-sensor scenarios: dataset and annotation approach</a>
            <br/>
            <u>Kevin Riou</u>, Kaiwen Dong, Yujie Huang, Kevin Subrin, Patrick Le Callet, Yanjing Sun
            <br/>
            IEEE International Conference on Image Processing (<b>ICIP</b>), 2024.
            <br/>
            Keywords: <strong> </strong>.
            <br/>
            [<a href="https://ieeexplore.ieee.org/abstract/document/10647858" target="_blank">PDF</a>]
            [<a href="javascript:toggleBibtex('riou2024evaluating')"   target=_self> Bibtex</a>]  
            <div id=riou2024evaluating class=blockcontent style="DISPLAY: none">
                <pre style="white-space: pre-wrap;">
                  @inproceedings{riou2024evaluating,
                    title={Evaluating 3d human pose estimation in occluded multi-sensor scenarios: dataset and annotation approach},
                    author={Riou, Kevin and Dong, Kaiwen and Huang, Yujie and Subrin, Kevin and Le Callet, Patrick and Sun, Yanjing},
                    booktitle={2024 IEEE International Conference on Image Processing (ICIP)},
                    pages={2683--2689},
                    year={2024},
                    organization={IEEE}
                  }
                  
                </pre>
            </div> 
        </span>
        </p>
                </td>
            </tr>
  
            
        </tbody>
    </table>
</font>
<br/>

<p><b>Action recognition</b>: </p>
<font size="2"> 
  <table>
      <tbody>


        <tr>
          <td  align="left">
              <img src="files/imgs/papers/aaai.png" width="310" />
          </td>
          <td height="92" style="text-align:left;">
              <p style="text-indent: 0rem;margin-left: 0rem;">
      <a>Behavioral Recognition of Skeletal Data Based on Targeted Dual Fusion Strategy</a>
      <br/>
      Xiao Yun, Chenglong Xu, <u>Kevin Riou</u>, Kaiwen Dong, Yanjing Sun, Song Li, Kevin Subrin, Patrick Le Callet
      <br/>
      Proceedings of the AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2024.
      <br/>
      [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28517" target="_blank">PDF</a>]
      [<a href="javascript:toggleBibtex('yun2024behavioral')"   target=_self> Bibtex</a>]  
      <div id=yun2024behavioral class=blockcontent style="DISPLAY: none">
          <pre style="white-space: pre-wrap;">
            @inproceedings{yun2024behavioral,
              title={Behavioral Recognition of Skeletal Data Based on Targeted Dual Fusion Strategy},
              author={Yun, Xiao and Xu, Chenglong and Riou, Kevin and Dong, Kaiwen and Sun, Yanjing and Li, Song and Subrin, Kevin and Le Callet, Patrick},
              booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
              volume={38},
              number={7},
              pages={6917--6925},
              year={2024}
            }
                       
            
          </pre>
      </div> 
  </span>
  </p>
          </td>
      </tr>

            
    </tbody>
  </table>
</font>
<br/>

<p><b>Imitation Learning</b>: </p>
<font size="2"> 
  <table>
      <tbody>


        <tr>
          <td  align="left">
              <img src="files/imgs/papers/iros_2024.png" width="310" />
          </td>
          <td height="92" style="text-align:left;">
              <p style="text-indent: 0rem;margin-left: 0rem;">
      <a>Vision Foundation Models for an embodiment and environment agnostic scene representation for robotic manipulation</a>
      <br/>
      <u>Kevin Riou</u>, Kevin Subrin, Patrick Le Callet
      <br/>
      IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), on Brain over Brawn Workshop (BoB)(https://bob-workshop. github. io/) , 2024.
      <br/>
      [<a href="https://hal.science/hal-04751375/" target="_blank">PDF</a>]
      [<a href="javascript:toggleBibtex('riou2024vision')"   target=_self> Bibtex</a>]  
      <div id=riou2024vision class=blockcontent style="DISPLAY: none">
          <pre style="white-space: pre-wrap;">
            @inproceedings{riou2024vision,
              title={Vision Foundation Models for an embodiment and environment agnostic scene representation for robotic manipulation},
              author={Riou, Kevin and Subrin, Kevin and Le Callet, Patrick},
              booktitle={International Conference on Intelligent Robots and Systems (IROS), on Brain over Brawn Workshop (BoB)(https://bob-workshop. github. io/)},
              year={2024}
            }
          </pre>
      </div> 
  </span>
  </p>
          </td>
      </tr>

      <tr>
        <td  align="left">
            <img src="files/imgs/papers/iros_2023.jpg" width="310" />
        </td>
        <td height="92" style="text-align:left;">
            <p style="text-indent: 0rem;margin-left: 0rem;">
    <a>From Temporal-evolving to Spatial-fixing: A Keypoints-based Learning Paradigm for Visual Robotic Manipulation</a>
    <br/>
    <u>Kevin Riou</u>, Kaiwen Dong, Kevin Subrin, Yanjing Sun, Patrick Le Callet
    <br/>
    IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), 2023.
    <br/>
    [<a href="https://ieeexplore.ieee.org/abstract/document/10341397" target="_blank">PDF</a>]
    [<a href="javascript:toggleBibtex('riou2023temporal')"   target=_self> Bibtex</a>]  
    <div id=riou2023temporal class=blockcontent style="DISPLAY: none">
        <pre style="white-space: pre-wrap;">
          @inproceedings{riou2023temporal,
            title={From Temporal-evolving to Spatial-fixing: A Keypoints-based Learning Paradigm for Visual Robotic Manipulation},
            author={Riou, Kevin and Dong, Kaiwen and Subrin, K{\'e}vin and Sun, Yanjing and Le Callet, Patrick},
            booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
            pages={1728--1734},
            year={2023},
            organization={IEEE}
          }
          
        </pre>
    </div> 
</span>
</p>
        </td>
    </tr>
            
    </tbody>
  </table>
</font>
<br/>

<p><b>Reinforcement learning based tactile exploration</b>: </p>
<font size="2"> 
  <table>
      <tbody>


        <tr>
          <td  align="left">
              <img src="files/imgs/papers/jstsp_tactile_explo.png" width="310" />
          </td>
          <td height="92" style="text-align:left;">
              <p style="text-indent: 0rem;margin-left: 0rem;">
      <a>Reinforcement Learning Based Tactile Sensing for Active point cloud Acquisition, Recognition and Localization</a>
      <br/>
      <u>Kevin Riou</u>, Kaiwen Dong, Kevin Subrin, Patrick Le Callet
      <br/>
      IEEE Journal of Selected Topics in Signal Processinge (<b>JSTSP</b>), 2024.
      <br/>
      [<a href="https://ieeexplore.ieee.org/abstract/document/10606195" target="_blank">PDF</a>]
      [<a href="javascript:toggleBibtex('riou2024reinforcement')"   target=_self> Bibtex</a>]  
      <div id=riou2024reinforcement class=blockcontent style="DISPLAY: none">
          <pre style="white-space: pre-wrap;">
            @article{riou2024reinforcement,
              title={Reinforcement Learning Based Tactile Sensing for Active point cloud Acquisition, Recognition and Localization},
              author={Riou, Kevin and Dong, Kaiwen and Subrin, Kevin and Le Callet, Patrick},
              journal={IEEE Journal of Selected Topics in Signal Processing},
              year={2024},
              publisher={IEEE}
            }
            
                       
            
          </pre>
      </div> 
  </span>
  </p>
          </td>
      </tr>

            
    </tbody>
  </table>
</font>

<font size="2"> 
  <table>
      <tbody>


        <tr>
          <td  align="left">
              <img src="files/imgs/papers/icme_2022.png" width="310" />
          </td>
          <td height="92" style="text-align:left;">
              <p style="text-indent: 0rem;margin-left: 0rem;">
      <a>Reinforcement Learning Based Point-Cloud Acquisition and Recognition Using Exploration-Classification Reward Combination</a>
      <br/>
      <u>Kevin Riou</u>, Kevin Subrin, Patrick Le Callet
      <br/>
      IEEE International Conference on Multimedia and Expo  (<b>ICME</b>), 2022.
      <br/>
      [<a href="https://ieeexplore.ieee.org/abstract/document/9859968" target="_blank">PDF</a>]
      [<a href="javascript:toggleBibtex('riou2022reinforcement')"   target=_self> Bibtex</a>]  
      <div id=riou2022reinforcement class=blockcontent style="DISPLAY: none">
          <pre style="white-space: pre-wrap;">
            @inproceedings{riou2022reinforcement,
              title={Reinforcement Learning Based Point-Cloud Acquisition and Recognition Using Exploration-Classification Reward Combination},
              author={Riou, Kevin and Subrin, Kevin and Le Callet, Patrick},
              booktitle={2022 IEEE International Conference on Multimedia and Expo (ICME)},
              pages={1--6},
              year={2022},
              organization={IEEE}
            }
            
                       
            
          </pre>
      </div> 
  </span>
  </p>
          </td>
      </tr>

      <tr>
        <td  align="left">
            <img src="files/imgs/papers/icip_haptic_gmance.png" width="310" />
        </td>
        <td height="92" style="text-align:left;">
            <p style="text-indent: 0rem;margin-left: 0rem;">
    <a>Seeing by haptic glance: Reinforcement learning based 3d object recognition</a>
    <br/>
    <u>Kevin Riou</u>, Suiyi Ling, Guillaume Gallot, Patrick Le Callet
    <br/>
    IEEE International Conference on Image Processing  (<b>ICIP</b>), 2021.
    <br/>
    [<a href="https://ieeexplore.ieee.org/abstract/document/9506734" target="_blank">PDF</a>]
    [<a href="javascript:toggleBibtex('riou2021seeing')"   target=_self> Bibtex</a>]  
    <div id=riou2021seeing class=blockcontent style="DISPLAY: none">
        <pre style="white-space: pre-wrap;">
          @inproceedings{riou2021seeing,
            title={Seeing by haptic glance: Reinforcement learning based 3d object recognition},
            author={Riou, Kevin and Ling, Suiyi and Gallot, Guillaume and Le Callet, Patrick},
            booktitle={2021 IEEE International Conference on Image Processing (ICIP)},
            pages={3637--3641},
            year={2021},
            organization={IEEE}
          }
          
          
                     
          
        </pre>
    </div> 
</span>
</p>
        </td>
    </tr>
            
    </tbody>
  </table>
</font>
<br/>

<p><b>Others</b>: </p>
<font size="2"> 
  <table>
      <tbody>


        <tr>
          <td  align="left">
              <!-- <img src="files/imgs/papers/imx.png" width="80" /> -->
              <video width="310"  controls autoplay muted loop>
                <source src="files/imgs/papers/imx.mov" type="video/mp4">
                Your browser does not support the video tag.
              </video> 
          </td>
          <td height="92" style="text-align:left;">
              <p style="text-indent: 0rem;margin-left: 0rem;">
      <a>Kinetic particles: from human pose estimation to an immersive and interactive piece of art questionning thought-movement relationships</a>
      <br/>
      Mickael Lafontaine, Julie Cloarec-Michaud, <u>Kevin Riou</u>, Yujie Huang, Kaiwen Dong, Patrick Le Callet
      <br/>
      ACM International Conference on Interactive Media Experiences (<b>IMX</b>), 2023.
      <br/>
      üèÜ Runner-up demo award üèÜ
      <br/>
      [<a href="https://dl.acm.org/doi/abs/10.1145/3573381.3597228" target="_blank">PDF</a>]
      [<a href="javascript:toggleBibtex('lafontaine2023kinetic')"   target=_self> Bibtex</a>]  
      <div id=lafontaine2023kinetic class=blockcontent style="DISPLAY: none">
          <pre style="white-space: pre-wrap;">
            @inproceedings{lafontaine2023kinetic,
              title={Kinetic particles: from human pose estimation to an immersive and interactive piece of art questionning thought-movement relationships.},
              author={Lafontaine, Mickael and Cloarec-Michaud, Julie and Riou, Kevin and Huang, Yujie and Dong, Kaiwen and Le Callet, Patrick},
              booktitle={Proceedings of the 2023 ACM International Conference on Interactive Media Experiences},
              pages={382--385},
              year={2023}
            }       
            
          </pre>
      </div> 
  </span>
  </p>
          </td>
      </tr>


        <tr>
          <td  align="left">
              <img src="files/imgs/papers/intrusion_detection.png" width="310" />
          </td>
          <td height="92" style="text-align:left;">
              <p style="text-indent: 0rem;margin-left: 0rem;">
      <a>Multi-layer perceptron for network intrusion detection: From a study on two recent data sets to deployment on automotive processor</a>
      <br/>
      Arnaud Rosay, <u>Kevin Riou</u>, Florent Carlier, Pascal Leroux
      <br/>
      Annals of Telecommunications, 2022.
      <br/>
      [<a href="https://link.springer.com/article/10.1007/s12243-021-00852-0" target="_blank">PDF</a>]
      [<a href="javascript:toggleBibtex('rosay2022multi')"   target=_self> Bibtex</a>]  
      <div id=rosay2022multi class=blockcontent style="DISPLAY: none">
          <pre style="white-space: pre-wrap;">
            @article{rosay2022multi,
              title={Multi-layer perceptron for network intrusion detection: From a study on two recent data sets to deployment on automotive processor},
              author={Rosay, Arnaud and Riou, Kevin and Carlier, Florent and Leroux, Pascal},
              journal={Annals of Telecommunications},
              volume={77},
              number={5},
              pages={371--394},
              year={2022},
              publisher={Springer}
            }
            
                       
            
          </pre>
      </div> 
  </span>
  </p>
          </td>
      </tr>


      <tr>
        <td  align="left">
            <img src="files/imgs/papers/cucumbers_mmsp.png" width="310" />
        </td>
        <td height="92" style="text-align:left;">
            <p style="text-indent: 0rem;margin-left: 0rem;">
    <a>Few-shot object detection in real life: case study on auto-harvest</a>
    <br/>
    <u>Kevin Riou</u>, Jingwen Zhu, Suiyi Ling, Mathis Piquet, Vincent Truffault, Patrick Le Callet
    <br/>
    IEEE International Workshop on Multimedia Signal Processing (<b>MMSP</b>), 2020.
    <br/>
    [<a href="https://ieeexplore.ieee.org/abstract/document/9287053" target="_blank">PDF</a>]
    [<a href="javascript:toggleBibtex('riou2020few')"   target=_self> Bibtex</a>]  
    <div id=riou2020few class=blockcontent style="DISPLAY: none">
        <pre style="white-space: pre-wrap;">
          @inproceedings{riou2020few,
            title={Few-shot object detection in real life: case study on auto-harvest},
            author={Riou, Kevin and Zhu, Jingwen and Ling, Suiyi and Piquet, Mathis and Truffault, Vincent and Le Callet, Patrick},
            booktitle={2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)},
            pages={1--6},
            year={2020},
            organization={IEEE}
          }
          
          
                     
          
        </pre>
    </div> 
</span>
</p>
        </td>
    </tr>
            
    </tbody>
  </table>
</font>


 
<A NAME="Services"><h2>Services</h2></A>
<font size="2"> 
<ul>
<li>Reviewer - IEEE International Conference on Multimedia and Expo (ICME)</li>
<li>Reviewer - IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</li>
<li>Reviewer - IEEE International Conference on Image Processing (ICIP)</li>
<li>Reviewer - European conference on signal processing (EUSIPCO)</li>
<li>Student volunteer (organization) - ACM International Conference on Interactive Media Experiences (IMX) 2023</li>
</ul>
</font>

 
<br />
<br /> 


<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>

<script>
$(function(){
    $(window).scroll(function(){  //If scroll
        var scrollt = document.documentElement.scrollTop + document.body.scrollTop; //Getting Height after scroll
        if( scrollt >400 )
        {  
            $("#back_top").fadeIn(400); 
        }
        else
        {
            $("#back_top").stop().fadeOut(400);
        }
    });

    $("#back_top").click(function(){ 

        $("html,body").animate({scrollTop:"0px"}, 200);

    }); 

});
</script>
</body>
</html>
